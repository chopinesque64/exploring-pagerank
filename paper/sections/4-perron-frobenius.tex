\documentclass[../exploring-pagerank.tex]{subfiles}

\begin{document}
	\subsection{Irreducibility}
	In a Markov chain, states $s_i$ and $s_j$ communicate if $\iterate{P}{k}_{ij} > 0$, for some nonnegative integer $k$. That is, there is a path of nonzero probability (a random walk) between states $s_i$ and $s_j$. Communicativity is easily shown to be an equivalence relation.

	Consider partitioning a Markov state space $\Omega$ of size $n$ into partitions $\Omega_1 = \{ s_i \}_{i\leq k}$ and $\Omega_2 = \{ s_j \}_{k < j \leq n}$. Moreover, suppose there are random walks from $\Omega_2$ to $\Omega_1$ but none the other way. Note that the chain eventually never visits states in $\Omega_2$; when $\Omega_1$ is a communicating class, the chain reduces to the states of $\Omega_1$. We model such reducibility of a Markov chain in a lower-triangular canonical form:
	\begin{equation*}
	    \label{eqn:reducible}
	    P =
	    \begin{bmatrix}
	        \omega_{1\to 1} & 0 \\
	         \omega_{2 \to 1} & \omega_{2 \to 2}
	    \end{bmatrix},
	\end{equation*}
	where $\omega_{1\to 1}$ and $\omega_{2\to 2}$ are substochastic square matrices representing transition probabilities within $\Omega_1$ and $\Omega_2$, respectively, and $\omega_{2 \to 1}$ holds the transition probabilities from $\Omega_2$ to $\Omega_1$. Note that when $\omega_{2\to 1} = 0$, the chain is disconnected and so \textit{completely} reducible.

	We say a Markov chain is irreducible if and only if it contains a single communicating class. Equivalently, a digraph is irreducible when it has no strongly connected components (SCCs) smaller than itself.\footnote{Note that A topological sort on a reducible graph can factorize it into its disjoint strongly-connected components.} An irreducible matrix is a matrix corresponding to such irreducible objects. Note that an irreducible matrix is nonnegative; the transition matrix motivation above shows the classes of reducibility and irreducibility arise through the arrangement of zeroes within the matrix. To find reducbility in a chain-graph, we simply attempt to permute the state-vertices in the underlying matrix to obtain the above canonical form.

	Consider further what reducibility means in a Markov chain. As time passes, the probability of visiting the pages in $\Omega_2$ drops to zero. To our iterative importance calculation, these pages will eventually appear not at all important, but there is no reason why they shouldn't be. We must not permit this artifact of the Web structure to corrupt our importance scores. For now, we take reducibility of a Markov chain as a hypothetical difficulty; later, we will see that the real Web is quite reducible and requires a less naÃ¯ve model to give convergent and unique importance scores.

	\subsection{Periodicity}
	Consider a Markov chain with states $s_i \in \mathcal{S}$. Let $D(s_i) = \{n\in \mathbb{Z}_{\geq 0} : \iterate{p}{n}_{ii} > 0 \} \subset \mathbb{N}$. Note that $D(s_i)$ is trivially nonempty, as $\iterate{p}{0}_{ii} = 1$ for all $s_i$. We observe that $D(s_i)$ is closed under addition, and so $D(s_i)$ forms a numerical semigroup under addition. We define the period of a state by $d(s_i)=\text{gcd}\{D(s_i)\}$. In other words, a random walk (a path where each step has nonzero probability) from state $s_i$ can only return to $s_i$ in multiples of $d(s_i)$ steps. Consider states $s_i$ and $s_j$ in the same communicating class.
	Thus, $\iterate{p}{m}_{ij} > 0$ and $\iterate{p}{n}_{ji} > 0$ for some nonnegative iterators. Otherwise stated, there is a random $m$-path from $s_i$ to $s_j$ and a a random $n$-path from $s_j$ to $s_i$.
		\begin{figure}[h]
		\centering \scalebox{0.75}{\begin{tikzpicture}[
			scale=0.6,
            > = stealth,
			shorten > = 1pt,
			auto,
			node distance = 3cm,
			semithick]

			\tikzstyle{every state}=[
			draw = black,
			thick,
			fill = white,
			minimum size = 4mm]

			\node[state] (a) {$s_i$};
			\node[state] (b) [right of=a] {$s_j$};

			\path[->] (a) edge [bend left=45] node {$m$-step} (b)
			          (a) edge [loop above]   node {$\ell$-step} (a)
			          (b) edge [bend left=45] node {$n$-step} (a);
		\end{tikzpicture}}
		\caption{Communicating States}
		\label{fig:markov}
	\end{figure}

	Figure \ref{fig:markov} illustrates these cycles. Note that there are random cycles of length $\ell \equiv m+n \pmod{d(s_i)}$ on state $s_i$. The communicativity of $s_i$ and $s_j$ implies $\iterate{p}{n+m}_{jj} > 0$ and $\iterate{p}{n + \ell + m}_{jj} > 0$. That is, there is a random $\ell$-cycle on $s_j$; moreover, there is a random cycle on $s_j$ that goes from $s_j$ to $s_i$ and returns to $s_i$ before terminating at $s_j$. Thus, $d(s_j) \mid \ell$. However, since we have shown that $s_i$ has a random $\ell$-cycle, we know that $d(s_j) \mid d(s_i)$. By the symmetry of $s_i$ and $s_j$, we find $d(s_i) \mid d(s_j)$, and so $d(s_i) = d(s_j)$ whenever $s_i$ and $s_j$ communicate. Thus, when $P$ is irreducible, $d(P)$ is well-defined; every state has the same period. When $d(P) = 1$, we say the Markov chain is aperiodic.

    \subsection{Primitivity}
    Consider now a periodic Markov chain -- that is, a Markov chain with $d(P) > 1$. Let $\{a_\alpha\}$ represent a divergent integer sequence where each $a_\alpha \notin D(s_i)$. Then, $\prob(X_{a_\alpha} = s_i \mid X_o = s_i) = \iterate{P}{a_\alpha}_{ii} = 0$ for all $\alpha$, and thus we do not converge on a unique limiting distribution $\pi_i > 0$. This flaw corresponds to the problem of Web graph cycles that we intuited earlier. Much more has been said on the conditional convergence of periodic Markov chains, but we will now confine this conversation to the aperiodic case.

    Suppose we have an aperiodic irreducible Markov chain, and recall $D(s_i)$, the numerical semigroup given above.\footnote{Markovian semigroups form an important part of ergodic theory, which we barely explore here.} For a semigroup $V$ with $d=\gcd(V)$, it can be shown that there exists an integer $N$ such that $v\equiv n \pmod{d}$ for any $v\in V$ and all $n \geq N$. Since we have supposed an aperiodic Markov chain, we have a coprime numerical semigroup. Thus, there is some bound $t_i$ beyond which $\iterate{p}{t}_{ii} > 0$ for all $t \geq t_i$ over all states. By the irreducibility of the chain, we have a $k = k_{(i,j)}$ for which $\iterate{p}{k}_{ij} > 0$. Thus, for $t \geq t_i + k$, we have the following:
    \begin{align*}
        \iterate{p}{t}_{ij} \geq \iterate{p}{t-k}_{ii} \iterate{P}{k}_{ij} > 0. && \text{(Chapman-Kolmogorov)}
    \end{align*}
    Let $t'_i = t_i + \max_{j\in\Omega}\{ k_{(i,j)} \}$. Thus, for $t \geq t'_i$, we have $\iterate{p}{t}_{xy} > 0$ for all $y\in\Omega$. Then, for $t \geq \max_{i\in\Omega}\{ t'_i \}$. We conclude that, for an irreducible aperiodic chain, there is a $t$ that gives $\iterate{p}{t}_{ij} > 0$ over all states, and so $P^t > 0$. We take this result as the definition of matrix primitivity.

    Primitivity is thus irreducibility plus aperiodicity. Recall that an only irreducible Markov chain requires an iterate-function of state pairs. However, a primitive chain guarantees that \textit{all} states communicate -- not just be a part of the same communicating class -- after $t$ transitions.

    Consider a primitive Markov chain with eigenpair $(v, \lambda)$. The underlying primitivity of the transition matrix $P$ gives $P^k v = \lambda^k v > 0$ for some iterate $k$ and forever thereafter, so we see the eigenpair must be positive. Take another eigenpair $(w, \gamma)$ such that $\norm{w} < \norm{v}$ and $\gamma = \rho(P)$. Then for all iterates $n$, we have
    \begin{equation*}
        \gamma^n w = P^n w \leq P^n v = \lambda^n v.
    \end{equation*}
    However, since we supposed $\norm{w} < \norm{v}$, we cannot have $\beta < \lambda$. By the inequality above, we must conclude $\beta = \lambda$, and so a primitive $P$ has only one eigenvalue on its spectral circle, namely the spectral radius itself. This eigenvalue is the dominant eigenvalue of $P$. Since all stochastic matrices have spectral radius 1, we conclude that primitive Markov chains have an eigenpair $(1, \pi)$. This is exactly what we want to satisfy our limiting distribution condition $\pi = \pi P$. The following spectral properties of primitive Markov chains should not be terribly surprising by now, but they are are quite beautiful.

	\subsection{Perron-Frobenius Theorem}
	Perron's theorem, proved in 1907, provided spectral properties of positive matrices -- most notably, that such matrices have only one eigenvalue on their spectral circle, the dominant eigenvalue $\lambda_1=\rho(A)$. However, Perron's results results did not generally apply to nonnegative matrices. Frobenius, however, realized irreducible matrices behave like positive matrices, except that they may have multiple eigenvalues that are roots of unity of $d(P)$. Primitive matrices, however, do have a dominant eigenvalue, as we have shown above. The Perron-Frobenius theorem, proved in 1912, gives the following properties for a primitive square matrix:
	\begin{enumerate}
		\item The spectral radius $\rho$ equals some real eigenvalue $\lambda_1$;
		\item This eigenvalue (the Perron root) is simple, and it is the only eigenvalue on the spectral circle;
		\item The Perron root has unique, strictly positive left and right eigenvectors (Perron vectors);
		\item These left and right Perron eigenvectors are, up to normalization, the only nonnegative eigenvectors of $A$.
	\end{enumerate}
	Note that the Perron root is a dominant eigenvalue; it is the unique $\lambda_1$ such that $|\lambda_1|>|\lambda_2|\geq\cdots\geq |\lambda_{n}|$ for all $\lambda \in \sigma(A)$. Recall that $A$ and $\transpose{A}$ share a spectrum, and a left eigenvector of $A$ is a right eigenvector of $\transpose{A}$.

	We will not prove the complete Perron-Frobenius theorem in this paper -- its full statement contains far more than we have given here -- although we have heretofore outlined some basic arguments for the properties we find useful for spectral ranking.
\end{document}
